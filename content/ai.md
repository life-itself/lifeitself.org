# Position on AI and AI Research

**Created: 13th April 2023**

## The only wise approach is to halt development of more powerful AI immediately

We call for an immediate, indefinite moratorium on continued advance in AI development because of the clear and present dangers of developing ever more powerful AI.

- AI does not need to involve "self-consciousness" to be an existential risk
- Even a super-intelligent machine with poor parameters, or errors could be a problem
- Wise course is clearly restriction: to go slow until the multitude of risks and unknowns are clarified
- Obvious collective action problems for private sector actors motivated by the profit motive

Such a halt, should happen until such time as there has a been widespread reflection and collective decision making to determine a wise course of advance.

## Wiser Technology Part I & II covering wise approaches to AI

In 2024 we created a two part series looking at wiser approaches to technology in the context of the [Second Renaissance](https://secondrenaissance.net/):

- [Technology as God: Technology and a Second Renaissance Part I](https://news.secondrenaissance.net/p/technology-as-god-technology-and)
- [Wiser Technology: Technology and a Second Renaissance Part II](https://news.secondrenaissance.net/p/wiser-technology-technology-and-a)

## Previous related writings

- [Two Year Olds Playing with Kalashnikovs - Humanity in the Age of AI](https://rufuspollock.com/2019/04/08/children-playing-with-sharp-knives-humanity-and-the-digital-age/)
- [Wisdom Gap](https://lifeitself.org/learn/wisdom-gap) - the "Wisdom Gap" names the idea that there is a large and growing gap between our technological capabilities and our capacity to use them wisely.

## Appendix

For more detail and discussion see: https://github.com/orgs/life-itself/discussions/403
